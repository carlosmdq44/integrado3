# Proyecto Integrador â€” Avances 1, 2 y 3

## ğŸ¯ Objetivo General
DiseÃ±ar e implementar un **pipeline ELT** escalable que integre datos de mÃºltiples fuentes, los cargue en un **Data Warehouse** y los transforme en datasets listos para anÃ¡lisis de negocio.  

El proyecto se desarrolla en **tres entregas**:
1. **Avance 1:** Pipeline ELT base con CSV Airbnb NYC â†’ DWH local (DuckDB).  
2. **Avance 2:** RecolecciÃ³n desde **APIs y Scraping**, contenerizaciÃ³n con Docker, validaciÃ³n en capa raw.  
3. **Avance 3:** Transformaciones avanzadas en **SQL/Python**, integraciÃ³n de datos no estructurados, validaciÃ³n de capas staging/core/gold.  

### Diagrama (ASCII â€“ Fallback)
```
FUENTES
  â”œâ”€ CSV: AB_NYC.csv
  â”œâ”€ APIs
  â””â”€ Scraping
        â”‚
        â–¼
EXTRACCIÃ“N (Python)
  â”œâ”€ extract_api.py (requests + retries)
  â”œâ”€ extract_scrape.py (BeautifulSoup)
  â””â”€ run_extract.py (config YAML)
        â”‚
        â–¼
RAW (data/raw)
  â”œâ”€ airbnb/ab_nyc_YYYYMMDD.csv
  â”œâ”€ external/*.json + _manifest.csv
  â””â”€ validate_raw.py â†’ docs/raw_validation_report.md
        â”‚
        â–¼
STAGING (DuckDB)
  â”œâ”€ staging.airbnb_listings_clean (cleaning, types, winsor)
  â”œâ”€ staging.listing_text_features (textoâ†’features)
  â””â”€ staging.external_* (JSON normalizado)
        â”‚
        â–¼
CORE (DuckDB)
  â”œâ”€ fact_listings
  â”œâ”€ core.listing_text_features
  â”œâ”€ core.dim_availability_bucket
  â””â”€ core.fact_listings_enriched
        â”‚
        â–¼
GOLD (DuckDB + CSV)
  â”œâ”€ avg_price_by_area.csv, room_type_offer.csv, ...
  â”œâ”€ avg_price_by_area_room
  â”œâ”€ availability_bucket_by_ng
  â”œâ”€ corr_availability_reviews_by_ng
  â””â”€ price_vs_text_features
        â”‚
        â–¼
CONSUMO
  â”œâ”€ notebooks/analisis_airbnb.ipynb
  â””â”€ Dashboards/BI (Tableau/PowerBI/QuickSight)

ORQUESTACIÃ“N / DEVOPS
  â”œâ”€ run.py (Avance 1)
  â”œâ”€ sql_runner.py / normalize_external.py (Avance 3)
  â”œâ”€ quality_checks.py / validate_transform.py
  â”œâ”€ Dockerfile (Extractor Avance 2)
  â”œâ”€ GitHub Actions (build/push image)
  â””â”€ Airflow (futuro)
```

---

## ğŸ—ï¸ Avance 1 â€” Pipeline ELT + Data Warehouse

**Fuente principal:**  
- CSV: `AB_NYC.csv` (Airbnb NYC dataset)

**Pipeline:**  
1) **Extract:** CSV â†’ `data/raw/airbnb/ab_nyc_YYYYMMDD.csv`  
2) **Load:** `raw.airbnb_listings` (DuckDB)  
3) **Transform:** staging (limpieza/tipos/winsor), core (modelo dimensional), gold (KPIs)  

**Capas DWH (DuckDB):**  
- `raw` â†’ crudo  
- `staging` â†’ limpio, tipificado, `price_winsor`  
- `core` â†’ hechos + dimensiones  
- `gold` â†’ datasets finales

**Resultados (gold):**  
- `avg_price_by_area.csv`  
- `room_type_offer.csv`  
- `room_type_revenue_proxy.csv`  
- `top_hosts.csv`  
- `availability_by_district.csv`  
- `reviews_monthly_by_ng.csv`  

**Notebook:** [`notebooks/analisis_airbnb.ipynb`](notebooks/analisis_airbnb.ipynb) con Q1â€“Q8.

---

## ğŸŒ Avance 2 â€” ExtracciÃ³n desde APIs y Scraping + Docker

**Scripts:**  
- `extract_api.py` (APIs, reintentos/timeout)  
- `extract_scrape.py` (BeautifulSoup, meta + links)  
- `run_extract.py` (lee `config/extract_config.yaml`)  
- `validate_raw.py` (reporte: `docs/raw_validation_report.md`)  

**Convenciones RAW:**  
- Nombres: `fuente_YYYYMMDDThhmmssZ.json` (UTF-8, `\n`)  
- Manifest: `data/raw/_manifest.csv` (source, type, path, bytes, sha256)

**Docker (extractor):**  
- Imagen base: `python:3.10-slim`  
- Instala `requirements.txt`  
- Copia `scripts/` y `config/`  
- `ENTRYPOINT` â†’ `run_extract.py`  

**Ejemplo de jobs (`config/extract_config.yaml`):**
```yaml
jobs:
  - type: api
    name: httpbin_get_ip
    endpoint: https://httpbin.org/ip
  - type: scrape
    name: python_org_home
    url: https://www.python.org/
```

---

## ğŸ”„ Avance 3 â€” Transformaciones avanzadas + integraciÃ³n no estructurado

**Objetivo:** integrar **no estructurado â†’ estructurado** y enriquecer **core** para nuevos **gold**.  

**Scripts clave:**  
- `normalize_external.py`  
  - Texto libre de `name` (listings) â†’ features: `has_wifi`, `has_pool`, `has_garden`, `is_luxury`, `near_subway`.  
  - Normaliza JSON externos a `staging.external_*`.  
- `sql_runner.py` (ejecuta SQL)  
- `sql/core_third.sql`  
  - `core.listing_text_features`  
  - `core.dim_availability_bucket`  
  - `core.fact_listings_enriched`  
- `sql/gold_third.sql`  
  - `gold.avg_price_by_area_room`  
  - `gold.availability_bucket_by_ng`  
  - `gold.corr_availability_reviews_by_ng`  
  - `gold.price_vs_text_features`  
- `validate_transform.py` (checks de existencia/coherencia)  

**Ejemplos de anÃ¡lisis nuevos:**  
- Impacto de `has_wifi` / `is_luxury` en precio.  
- CorrelaciÃ³n entre `availability_365` y `number_of_reviews` por distrito.  
- Buckets de disponibilidad (`0â€“60`, `61â€“180`, `181â€“300`, `301â€“365`).  

---

## ğŸ“‚ Estructura consolidada del proyecto

```
elt_airbnb_nyc/
â”œâ”€ data/
â”‚  â”œâ”€ raw/               # CSV/JSON originales
â”‚  â”œâ”€ staging/           # CSV limpios / features tabulares
â”‚  â”œâ”€ core/              # modelo de negocio
â”‚  â”œâ”€ gold/              # datasets finales
â”‚  â””â”€ warehouse.duckdb   # DWH local
â”œâ”€ scripts/
â”‚  â”œâ”€ extract_*.py       # extracciÃ³n (APIs, scraping)
â”‚  â”œâ”€ normalize_external.py
â”‚  â”œâ”€ sql_runner.py
â”‚  â”œâ”€ validate_transform.py
â”‚  â””â”€ quality_checks.py
â”œâ”€ sql/                  # transformaciones SQL (core, gold)
â”œâ”€ config/               # extract_config.yaml
â”œâ”€ notebooks/            # analisis_airbnb.ipynb
â”œâ”€ docs/                 # documentaciÃ³n + reportes
â”œâ”€ Dockerfile            # extractor (avance 2)
â””â”€ run.py                # pipeline avance 1
```

---

## âœ… Estado de entregas

- **Avance 1**  
  - [x] Pipeline ELT (CSV â†’ raw â†’ staging â†’ core â†’ gold)  
  - [x] Respuestas Q1â€“Q8 en notebook  

- **Avance 2**  
  - [x] ExtracciÃ³n APIs + Scraping (YAML configurable)  
  - [x] ValidaciÃ³n capa raw + reporte  
  - [x] ContenerizaciÃ³n con Docker  

- **Avance 3**  
  - [x] Transformaciones avanzadas SQL/Python  
  - [x] IntegraciÃ³n datos no estructurados (texto + JSON externos)  
  - [x] ValidaciÃ³n de staging/core/gold  
